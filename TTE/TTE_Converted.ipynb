{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n"
     ]
    }
   ],
   "source": [
    "file_path = \"extraction/data_censored.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "try:\n",
    "    data_censored = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(data_censored.head())  # Display the first few rows\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for saving results\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trial_name': 'ITT', 'data':      id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
      "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
      "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
      "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
      "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
      "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
      "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
      "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
      "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
      "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
      "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
      "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
      "\n",
      "     outcome  censored  eligible  \n",
      "0          0         0         1  \n",
      "1          0         0         0  \n",
      "2          0         0         0  \n",
      "3          0         0         0  \n",
      "4          0         0         0  \n",
      "..       ...       ...       ...  \n",
      "720        0         0         0  \n",
      "721        0         0         0  \n",
      "722        0         0         0  \n",
      "723        0         0         0  \n",
      "724        1         0         0  \n",
      "\n",
      "[725 rows x 12 columns], 'id': 0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "720    99\n",
      "721    99\n",
      "722    99\n",
      "723    99\n",
      "724    99\n",
      "Name: id, Length: 725, dtype: int64, 'period': 0      0\n",
      "1      1\n",
      "2      2\n",
      "3      3\n",
      "4      4\n",
      "      ..\n",
      "720    3\n",
      "721    4\n",
      "722    5\n",
      "723    6\n",
      "724    7\n",
      "Name: period, Length: 725, dtype: int64, 'treatment': 0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "720    0\n",
      "721    0\n",
      "722    1\n",
      "723    1\n",
      "724    0\n",
      "Name: treatment, Length: 725, dtype: int64, 'outcome': 0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "720    0\n",
      "721    0\n",
      "722    0\n",
      "723    0\n",
      "724    1\n",
      "Name: outcome, Length: 725, dtype: int64, 'eligible': 0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "720    0\n",
      "721    0\n",
      "722    0\n",
      "723    0\n",
      "724    0\n",
      "Name: eligible, Length: 725, dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a function to structure the trial data\n",
    "def set_data(trial_name, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "    \"\"\"Prepare a dictionary to structure trial data.\"\"\"\n",
    "    return {\n",
    "        \"trial_name\": trial_name,\n",
    "        \"data\": data,\n",
    "        \"id\": data[id_col],\n",
    "        \"period\": data[period_col],\n",
    "        \"treatment\": data[treatment_col],\n",
    "        \"outcome\": data[outcome_col],\n",
    "        \"eligible\": data[eligible_col],\n",
    "    }\n",
    "\n",
    "# Per-Protocol (PP)\n",
    "trial_pp = set_data(\n",
    "    trial_name=\"PP\",\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    ")\n",
    "\n",
    "# Intention-To-Treat (ITT)\n",
    "trial_itt = set_data(\n",
    "    trial_name=\"ITT\",\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    ")\n",
    "\n",
    "# Print the structured ITT trial data\n",
    "print(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.662406\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660234\n",
      "         Iterations 5\n",
      "   id  switch_weight\n",
      "0   1       0.930088\n",
      "1   1       0.928634\n",
      "2   1       1.039459\n",
      "3   1       1.040816\n",
      "4   1       0.924292\n"
     ]
    }
   ],
   "source": [
    "# Define directory for saving models\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "# Separate data for treatment = 1 and treatment = 0 in the previous period\n",
    "data_treated = data_censored[data_censored['treatment'].shift(1) == 1]\n",
    "data_untreated = data_censored[data_censored['treatment'].shift(1) == 0]\n",
    "\n",
    "# Define function to fit logistic regression models\n",
    "def fit_logit_model(data, formula, save_path):\n",
    "    \"\"\"Fits a logistic regression model and saves it.\"\"\"\n",
    "    y = data['treatment']  # Dependent variable (treatment in current period)\n",
    "    X = data[formula]  # Independent variables\n",
    "    X = sm.add_constant(X)  # Add intercept term\n",
    "    \n",
    "    model = sm.Logit(y, X).fit()\n",
    "    \n",
    "    # Save model summary\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(model.summary().as_text())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit numerator model (only age as predictor)\n",
    "numerator_model = fit_logit_model(data_censored, [\"age\"], os.path.join(trial_pp_dir, \"switch_numerator_model.txt\"))\n",
    "\n",
    "# Fit denominator model (age + x1 + x3 as predictors)\n",
    "denominator_model = fit_logit_model(data_censored, [\"age\", \"x1\", \"x3\"], os.path.join(trial_pp_dir, \"switch_denominator_model.txt\"))\n",
    "\n",
    "# Compute stabilized weights\n",
    "data_censored[\"numerator_prob\"] = numerator_model.predict(sm.add_constant(data_censored[[\"age\"]]))\n",
    "data_censored[\"denominator_prob\"] = denominator_model.predict(sm.add_constant(data_censored[[\"age\", \"x1\", \"x3\"]]))\n",
    "data_censored[\"switch_weight\"] = data_censored[\"numerator_prob\"] / data_censored[\"denominator_prob\"]\n",
    "\n",
    "# Print first few switch weights\n",
    "print(data_censored[[\"id\", \"switch_weight\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.271311\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.267425\n",
      "         Iterations 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  censor_weight\n",
      "0   1       1.475475\n",
      "1   1       1.537091\n",
      "2   1       0.806712\n",
      "3   1       0.801936\n",
      "4   1       1.526032\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.245318\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.239480\n",
      "         Iterations 7\n",
      "   id  censor_weight_itt\n",
      "0   1           1.452909\n",
      "1   1           1.835148\n",
      "2   1           0.786148\n",
      "3   1           0.774288\n",
      "4   1           1.817616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define directories for saving models\n",
    "\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Define function to fit logistic regression models\n",
    "def fit_logit_model(data, formula_vars, dependent_var, save_path):\n",
    "    \"\"\"Fits a logistic regression model and saves it.\"\"\"\n",
    "    y = data[dependent_var]  # Dependent variable (censoring event)\n",
    "    X = data[formula_vars]  # Independent variables\n",
    "    X = sm.add_constant(X)  # Add intercept term\n",
    "    \n",
    "    model = sm.Logit(y, X).fit()\n",
    "    \n",
    "    # Save model summary\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(model.summary().as_text())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit numerator model: 1 - censored ~ x2\n",
    "numerator_model_pp = fit_logit_model(\n",
    "    data_censored, \n",
    "    [\"x2\"], \n",
    "    \"censored\", \n",
    "    os.path.join(trial_pp_dir, \"censor_numerator_model.txt\")\n",
    ")\n",
    "\n",
    "# Fit denominator model: 1 - censored ~ x2 + x1\n",
    "denominator_model_pp = fit_logit_model(\n",
    "    data_censored, \n",
    "    [\"x2\", \"x1\"], \n",
    "    \"censored\", \n",
    "    os.path.join(trial_pp_dir, \"censor_denominator_model.txt\")\n",
    ")\n",
    "\n",
    "# Compute stabilized censoring weights\n",
    "data_censored[\"censor_numerator_prob\"] = numerator_model_pp.predict(sm.add_constant(data_censored[[\"x2\"]]))\n",
    "data_censored[\"censor_denominator_prob\"] = denominator_model_pp.predict(sm.add_constant(data_censored[[\"x2\", \"x1\"]]))\n",
    "data_censored[\"censor_weight\"] = data_censored[\"censor_numerator_prob\"] / data_censored[\"censor_denominator_prob\"]\n",
    "\n",
    "# Print first few censoring weights\n",
    "print(data_censored[[\"id\", \"censor_weight\"]].head())\n",
    "\n",
    "# Fit numerator model: 1 - censored ~ x2 + assigned_treatment\n",
    "numerator_model_itt = fit_logit_model(\n",
    "    data_censored, \n",
    "    [\"x2\", \"eligible\"], \n",
    "    \"censored\", \n",
    "    os.path.join(trial_itt_dir, \"censor_numerator_model.txt\")\n",
    ")\n",
    "\n",
    "# Fit denominator model: 1 - censored ~ x2 + x1 + assigned_treatment\n",
    "denominator_model_itt = fit_logit_model(\n",
    "    data_censored, \n",
    "    [\"x2\", \"x1\", \"eligible\"],  \n",
    "    \"censored\", \n",
    "    os.path.join(trial_itt_dir, \"censor_denominator_model.txt\")\n",
    ")\n",
    "\n",
    "# Compute weights for ITT\n",
    "data_censored[\"censor_numerator_prob_itt\"] = numerator_model_itt.predict(sm.add_constant(data_censored[[\"x2\", \"eligible\"]]))\n",
    "data_censored[\"censor_denominator_prob_itt\"] = denominator_model_itt.predict(sm.add_constant(data_censored[[\"x2\", \"x1\", \"eligible\"]]))\n",
    "data_censored[\"censor_weight_itt\"] = data_censored[\"censor_numerator_prob_itt\"] / data_censored[\"censor_denominator_prob_itt\"]\n",
    "\n",
    "# Print ITT censoring weights\n",
    "print(data_censored[[\"id\", \"censor_weight_itt\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.271311\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        19:03:18   Log-Likelihood:                -196.70\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4481      0.141     17.415      0.000       2.173       2.724\n",
      "x2            -0.4486      0.137     -3.278      0.001      -0.717      -0.180\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.267425\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      722\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.04069\n",
      "Time:                        19:03:18   Log-Likelihood:                -193.88\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0002679\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.2059      0.165     13.339      0.000       1.882       2.530\n",
      "x2            -0.4706      0.137     -3.423      0.001      -0.740      -0.201\n",
      "x1             0.7019      0.307      2.285      0.022       0.100       1.304\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fit censoring model (numerator)\n",
    "X_n = sm.add_constant(data_censored[['x2']])  # Predictor variables\n",
    "y_n = 1 - data_censored['censored']           # Outcome variable (not censored)\n",
    "censor_model_n = sm.Logit(y_n, X_n).fit()\n",
    "print(censor_model_n.summary())\n",
    "\n",
    "# Fit censoring model (denominator)\n",
    "X_d = sm.add_constant(data_censored[['x2', 'x1']])  \n",
    "y_d = 1 - data_censored['censored']  \n",
    "censor_model_d = sm.Logit(y_d, X_d).fit()\n",
    "print(censor_model_d.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.662406\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.04144\n",
      "Time:                        19:03:18   Log-Likelihood:                -480.24\n",
      "converged:                       True   LL-Null:                       -501.01\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.163e-10\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.8867      0.333      5.671      0.000       1.235       2.539\n",
      "age           -0.0421      0.007     -6.213      0.000      -0.055      -0.029\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660234\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      721\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.04459\n",
      "Time:                        19:03:18   Log-Likelihood:                -478.67\n",
      "converged:                       True   LL-Null:                       -501.01\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.084e-09\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.8308      0.356      5.145      0.000       1.133       2.528\n",
      "age           -0.0429      0.007     -6.261      0.000      -0.056      -0.029\n",
      "x1             0.2744      0.157      1.752      0.080      -0.033       0.581\n",
      "x3            -0.0321      0.155     -0.207      0.836      -0.336       0.272\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fit treatment switching model (numerator)\n",
    "X_tn = sm.add_constant(data_censored[['age']])  \n",
    "y_tn = data_censored['treatment']  \n",
    "switch_model_n = sm.Logit(y_tn, X_tn).fit()\n",
    "print(switch_model_n.summary())\n",
    "\n",
    "# Fit treatment switching model (denominator)\n",
    "X_td = sm.add_constant(data_censored[['age', 'x1', 'x3']])  \n",
    "y_td = data_censored['treatment']  \n",
    "switch_model_d = sm.Logit(y_td, X_td).fit()\n",
    "print(switch_model_d.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078303\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                0.003823\n",
      "Time:                        19:03:19   Log-Likelihood:                -56.769\n",
      "converged:                       True   LL-Null:                       -56.987\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.5092\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.1577      0.304    -13.677      0.000      -4.753      -3.562\n",
      "x2             0.1993      0.300      0.664      0.507      -0.389       0.788\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define predictors\n",
    "X = sm.add_constant(data_censored[['x2']])  # Adjusting for x2\n",
    "y = data_censored['outcome']  \n",
    "\n",
    "# Fit logistic regression model\n",
    "outcome_model = sm.Logit(y, X).fit()\n",
    "print(outcome_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['final_weight_pp', 'final_weight_itt'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check if the weight columns are actually different\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m weight_check \u001b[38;5;241m=\u001b[39m \u001b[43mdata_censored\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_weight_pp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_weight_itt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(weight_check\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))  \u001b[38;5;66;03m# Show first 10 unique rows\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Check for differences\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\suzuk\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\suzuk\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\suzuk\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['final_weight_pp', 'final_weight_itt'] not in index\""
     ]
    }
   ],
   "source": [
    "# Check if the weight columns are actually different\n",
    "weight_check = data_censored[['id', 'final_weight_pp', 'final_weight_itt']].drop_duplicates()\n",
    "print(weight_check.head(10))  # Show first 10 unique rows\n",
    "\n",
    "# Check for differences\n",
    "diff_check = (data_censored['final_weight_pp'] != data_censored['final_weight_itt']).sum()\n",
    "print(f\"Number of differing rows: {diff_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final stabilized weights\n",
    "data_censored[\"final_weight_pp\"] = data_censored[\"switch_weight\"] * data_censored[\"censor_weight\"]\n",
    "data_censored[\"final_weight_itt\"] = data_censored[\"switch_weight\"] * data_censored[\"censor_weight_itt\"]\n",
    "\n",
    "# Print first few rows to compare\n",
    "print(data_censored[[\"id\", \"final_weight_pp\", \"final_weight_itt\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_trials(data, max_followup=10, trial_type=\"PP\"):\n",
    "    expanded_rows = []\n",
    "    \n",
    "    # Select weight column based on trial type\n",
    "    if trial_type == \"PP\":\n",
    "        weight_col = \"final_weight_pp\"\n",
    "    elif trial_type == \"ITT\":\n",
    "        weight_col = \"final_weight_itt\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid trial type. Choose 'PP' or 'ITT'.\")\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        for t in range(max_followup):  \n",
    "            expanded_rows.append({\n",
    "                'id': row['id'],\n",
    "                'trial_period': t,\n",
    "                'followup_time': t,\n",
    "                'outcome': row['outcome'],  \n",
    "                'weight': row[weight_col],  # Use correct weight column\n",
    "                'treatment': row['treatment'],\n",
    "                'x2': row['x2'],\n",
    "                'age': row['age'],\n",
    "                'assigned_treatment': row['treatment']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Expand PP trial\n",
    "expanded_data_pp = expand_trials(data_censored, trial_type=\"PP\")\n",
    "\n",
    "# Expand ITT trial\n",
    "expanded_data_itt = expand_trials(data_censored, trial_type=\"ITT\")\n",
    "\n",
    "# Check output\n",
    "print(expanded_data_pp.head())\n",
    "print(expanded_data_itt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_censored.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_censored[[\"id\", \"final_weight_pp\", \"final_weight_itt\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expanded_data(data, seed=1234, p_control=0.5):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # If p_control < 1, randomly drop some outcome == 0 rows\n",
    "    if p_control < 1:\n",
    "        control_mask = (data[\"outcome\"] == 0)  # Identify control cases\n",
    "        sample_mask = control_mask & (np.random.rand(len(data)) > p_control)\n",
    "        data = data[~sample_mask]  # Drop some controls\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load ITT trial data with sampling\n",
    "expanded_data_itt = load_expanded_data(expanded_data_itt, seed=1234, p_control=0.5)\n",
    "expanded_data_pp = load_expanded_data(expanded_data_pp, seed=1234, p_control=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_msm(data, weight_cols):\n",
    "    \"\"\" Fits a logistic regression model (MSM) using stabilized inverse probability weights. \"\"\"\n",
    "    \n",
    "    # Winsorization function to cap extreme weights at 99th percentile\n",
    "    def modify_weights(weights):\n",
    "        q99 = np.quantile(weights, 0.99)\n",
    "        return np.minimum(weights, q99)  # Cap weights at 99th percentile\n",
    "\n",
    "    # Get weights and apply winsorization\n",
    "    weights = modify_weights(data[weight_cols].sum(axis=1))  \n",
    "\n",
    "    # Define independent variables (formula-like structure)\n",
    "    data[\"followup_time_sq\"] = data[\"followup_time\"] ** 2\n",
    "    data[\"trial_period_sq\"] = data[\"trial_period\"] ** 2\n",
    "\n",
    "    independent_vars = [\"assigned_treatment\", \"x2\", \"followup_time\", \"followup_time_sq\", \"trial_period\", \"trial_period_sq\"]\n",
    "    X = sm.add_constant(data[independent_vars])  # Add intercept\n",
    "    y = data[\"outcome\"]  # Dependent variable\n",
    "\n",
    "    # Fit logistic regression (equivalent to glm with binomial logit in R)\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial(), freq_weights=weights).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit MSM on ITT trial data\n",
    "msm_model_pp = fit_msm(expanded_data_pp, weight_cols=[\"weight\"])\n",
    "msm_model_itt = fit_msm(expanded_data_itt, weight_cols=[\"weight\"])\n",
    "\n",
    "# Print model summary (like R's `trial_itt@outcome_model`)\n",
    "print(msm_model_pp.summary())\n",
    "print(msm_model_itt.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance-covariance matrix\n",
    "vcov_matrix_itt = msm_model_itt.cov_params()\n",
    "vcov_matrix_pp = msm_model_pp.cov_params()\n",
    "print(vcov_matrix_pp)\n",
    "print(vcov_matrix_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Step 1: Fit a Kaplan-Meier Survival Model for ITT trial\n",
    "kmf_treated = KaplanMeierFitter()\n",
    "kmf_control = KaplanMeierFitter()\n",
    "\n",
    "# Subset data for assigned_treatment = 1 (treated) and 0 (control)\n",
    "data_treated = expanded_data_itt[expanded_data_itt[\"assigned_treatment\"] == 1]\n",
    "data_control = expanded_data_itt[expanded_data_itt[\"assigned_treatment\"] == 0]\n",
    "\n",
    "# Fit Kaplan-Meier survival curves\n",
    "kmf_treated.fit(data_treated[\"followup_time\"], event_observed=data_treated[\"outcome\"], label=\"Treated\")\n",
    "kmf_control.fit(data_control[\"followup_time\"], event_observed=data_control[\"outcome\"], label=\"Control\")\n",
    "\n",
    "# Step 2: Predict survival probabilities over time\n",
    "followup_times = np.arange(0, 11)  # Predict for 0 to 10 follow-up periods\n",
    "survival_treated = kmf_treated.survival_function_at_times(followup_times)\n",
    "survival_control = kmf_control.survival_function_at_times(followup_times)\n",
    "\n",
    "# Compute the survival difference\n",
    "survival_diff = survival_treated - survival_control\n",
    "# Step 3: Plot Survival Difference\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(followup_times, survival_diff, label=\"Survival Difference\", color=\"blue\")\n",
    "\n",
    "# Confidence intervals (assuming normal approximation)\n",
    "std_error = np.sqrt(survival_treated * (1 - survival_treated) / len(data_treated) +\n",
    "                    survival_control * (1 - survival_control) / len(data_control))\n",
    "\n",
    "ci_lower = survival_diff - 1.96 * std_error\n",
    "ci_upper = survival_diff + 1.96 * std_error\n",
    "\n",
    "# Add confidence interval lines\n",
    "plt.plot(followup_times, ci_lower, color=\"red\", linestyle=\"dashed\", label=\"2.5% CI\")\n",
    "plt.plot(followup_times, ci_upper, color=\"red\", linestyle=\"dashed\", label=\"97.5% CI\")\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"Follow-up Time\")\n",
    "plt.ylabel(\"Survival Difference\")\n",
    "plt.title(\"Survival Difference Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
